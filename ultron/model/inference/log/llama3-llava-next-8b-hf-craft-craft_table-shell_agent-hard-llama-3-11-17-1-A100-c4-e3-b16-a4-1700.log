INFO 11-19 07:03:18 api_server.py:528] vLLM API server version 0.6.3.post1
INFO 11-19 07:03:18 api_server.py:529] args: Namespace(subparser='serve', model_tag='/scratch/mc_lmy/models/llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4-1700', config='', host=None, port=9207, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='/scratch/mc_lmy/models/llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4-1700', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=True, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=4096, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=2, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.95, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=False, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt={'image': 4}, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7fb40be10790>)
INFO 11-19 07:03:18 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/18ad5654-19d8-4ef0-9f3d-e4e1a244c73e for IPC Path.
INFO 11-19 07:03:18 api_server.py:179] Started engine process with PID 3473896
INFO 11-19 07:03:25 config.py:905] Defaulting to use mp for distributed inference
WARNING 11-19 07:03:25 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.
INFO 11-19 07:03:29 config.py:905] Defaulting to use mp for distributed inference
WARNING 11-19 07:03:29 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.
INFO 11-19 07:03:29 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='/scratch/mc_lmy/models/llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4-1700', speculative_config=None, tokenizer='/scratch/mc_lmy/models/llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4-1700', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/scratch/mc_lmy/models/llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4-1700, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, mm_processor_kwargs=None)
WARNING 11-19 07:03:30 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
INFO 11-19 07:03:30 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:34 multiproc_worker_utils.py:215] Worker ready; awaiting tasks
INFO 11-19 07:03:35 utils.py:1008] Found nccl from library libnccl.so.2
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:35 utils.py:1008] Found nccl from library libnccl.so.2
INFO 11-19 07:03:35 pynccl.py:63] vLLM is using nccl==2.20.5
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:35 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 11-19 07:03:35 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/mc_lmy/.cache/vllm/gpu_p2p_access_cache_for_6,7.json
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:35 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/mc_lmy/.cache/vllm/gpu_p2p_access_cache_for_6,7.json
INFO 11-19 07:03:35 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7ff16bc55180>, local_subscribe_port=53097, remote_subscribe_port=None)
INFO 11-19 07:03:35 model_runner.py:1056] Starting to load model /scratch/mc_lmy/models/llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4-1700...
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:35 model_runner.py:1056] Starting to load model /scratch/mc_lmy/models/llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4-1700...
[1;36m(VllmWorkerProcess pid=3474563)[0;0m /home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4
[1;36m(VllmWorkerProcess pid=3474563)[0;0m   warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
[1;36m(VllmWorkerProcess pid=3474563)[0;0m /home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
[1;36m(VllmWorkerProcess pid=3474563)[0;0m   @torch.library.impl_abstract("xformers_flash::flash_fwd")
[1;36m(VllmWorkerProcess pid=3474563)[0;0m /home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
[1;36m(VllmWorkerProcess pid=3474563)[0;0m   @torch.library.impl_abstract("xformers_flash::flash_bwd")
/home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:02<00:08,  2.73s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:05<00:05,  2.75s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:08<00:02,  2.82s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:09<00:00,  2.17s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:09<00:00,  2.39s/it]

INFO 11-19 07:03:46 model_runner.py:1067] Loading model weights took 7.7991 GB
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:46 model_runner.py:1067] Loading model weights took 7.7991 GB
WARNING 11-19 07:03:46 model_runner.py:1247] Computed max_num_seqs (min(256, 5120 // 11712)) to be less than 1. Setting it to the minimum value of 1.
[1;36m(VllmWorkerProcess pid=3474563)[0;0m WARNING 11-19 07:03:46 model_runner.py:1247] Computed max_num_seqs (min(256, 5120 // 11712)) to be less than 1. Setting it to the minimum value of 1.
INFO 11-19 07:03:47 distributed_gpu_executor.py:57] # GPU blocks: 66051, # CPU blocks: 4096
INFO 11-19 07:03:47 distributed_gpu_executor.py:61] Maximum concurrency for 4096 tokens per request: 258.01x
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:49 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:03:49 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 11-19 07:03:49 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 11-19 07:03:49 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:04:02 custom_all_reduce.py:233] Registering 2275 cuda graph addresses
INFO 11-19 07:04:02 custom_all_reduce.py:233] Registering 2275 cuda graph addresses
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:04:02 model_runner.py:1523] Graph capturing finished in 13 secs.
INFO 11-19 07:04:02 model_runner.py:1523] Graph capturing finished in 13 secs.
INFO 11-19 07:04:03 api_server.py:232] vLLM to use /tmp/tmpitenu7py as PROMETHEUS_MULTIPROC_DIR
WARNING 11-19 07:04:03 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.
INFO 11-19 07:04:03 launcher.py:19] Available routes are:
INFO 11-19 07:04:03 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD
INFO 11-19 07:04:03 launcher.py:27] Route: /docs, Methods: GET, HEAD
INFO 11-19 07:04:03 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 11-19 07:04:03 launcher.py:27] Route: /redoc, Methods: GET, HEAD
INFO 11-19 07:04:03 launcher.py:27] Route: /health, Methods: GET
INFO 11-19 07:04:03 launcher.py:27] Route: /tokenize, Methods: POST
INFO 11-19 07:04:03 launcher.py:27] Route: /detokenize, Methods: POST
INFO 11-19 07:04:03 launcher.py:27] Route: /v1/models, Methods: GET
INFO 11-19 07:04:03 launcher.py:27] Route: /version, Methods: GET
INFO 11-19 07:04:03 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 11-19 07:04:03 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 11-19 07:04:03 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     Started server process [3473772]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on socket ('0.0.0.0', 9207) (Press CTRL+C to quit)
INFO 11-19 07:04:13 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:46262 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46266 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46274 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46288 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46298 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46314 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46330 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46334 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46350 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46360 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46374 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46386 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46394 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46410 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46412 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46414 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46416 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46418 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46428 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46444 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46454 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46466 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46472 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46482 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46486 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:46502 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54592 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54600 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54614 - "GET /v1/models HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "GET /v1/models HTTP/1.1" 200 OK
INFO 11-19 07:04:23 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 11-19 07:04:33 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 11-19 07:04:43 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 11-19 07:04:53 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 11-19 07:05:03 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 11-19 07:05:13 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 11-19 07:05:22 logger.py:37] Received request chat-97bc9f3b4fbb4e829a05768f7d0db1df: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
/home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
INFO 11-19 07:05:23 metrics.py:349] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 11-19 07:05:25 logger.py:37] Received request chat-389c69e51eb3400f8968cfcd21526e99: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:25 logger.py:37] Received request chat-35badc86a5844e82ad67e3a252fc5581: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:25 logger.py:37] Received request chat-cb6d4a123d7047cda56454a4785183b0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:25 logger.py:37] Received request chat-9a18ffd99fcd4e03929145eaa26d289f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:25 logger.py:37] Received request chat-25396c0fc5b74c9ea4ef2df16156e9d5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:25 logger.py:37] Received request chat-74cf2a837ed44c4b899db8e223c8e848: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:25 logger.py:37] Received request chat-4a167a7042c74c0d8da6ee664a1e4b33: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:26 logger.py:37] Received request chat-307eb064ea804d2681460bd65b376013: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:26 logger.py:37] Received request chat-514d4d02800a4cca9d39eb6b47914e5b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:26 engine.py:290] Added request chat-97bc9f3b4fbb4e829a05768f7d0db1df.
INFO 11-19 07:05:26 engine.py:290] Added request chat-389c69e51eb3400f8968cfcd21526e99.
INFO 11-19 07:05:26 engine.py:290] Added request chat-35badc86a5844e82ad67e3a252fc5581.
INFO 11-19 07:05:26 engine.py:290] Added request chat-cb6d4a123d7047cda56454a4785183b0.
INFO 11-19 07:05:26 engine.py:290] Added request chat-9a18ffd99fcd4e03929145eaa26d289f.
INFO 11-19 07:05:26 engine.py:290] Added request chat-25396c0fc5b74c9ea4ef2df16156e9d5.
INFO 11-19 07:05:26 engine.py:290] Added request chat-74cf2a837ed44c4b899db8e223c8e848.
INFO 11-19 07:05:26 engine.py:290] Added request chat-4a167a7042c74c0d8da6ee664a1e4b33.
INFO 11-19 07:05:26 engine.py:290] Added request chat-307eb064ea804d2681460bd65b376013.
INFO 11-19 07:05:26 engine.py:290] Added request chat-514d4d02800a4cca9d39eb6b47914e5b.
[1;36m(VllmWorkerProcess pid=3474563)[0;0m /home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
[1;36m(VllmWorkerProcess pid=3474563)[0;0m   return torch.load(io.BytesIO(b))
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:28 logger.py:37] Received request chat-0b8a2108d42549afa3cb7514967b5c52: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 engine.py:290] Added request chat-0b8a2108d42549afa3cb7514967b5c52.
INFO 11-19 07:05:28 logger.py:37] Received request chat-3dd0ae9d6f054ce393241c2774198782: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-904c8657d7ad42e9b3549325a4ff3758: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-257f5e1c611c4e27b9a424f50fa5cdb6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-ef1db9fa5cf34a4994a56d59f559fa8d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-7a1fe48da8454801a8d47807490e0f07: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-aa484b2bed4945aa97a260780eee1380: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-ae5ca99db8e844409f5f70776182b3c4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-f5cf657361c14c2fb5b24537ce9f9cc7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 logger.py:37] Received request chat-8008efbf51a84132bb61f8b0b0aee4dd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:28 engine.py:290] Added request chat-3dd0ae9d6f054ce393241c2774198782.
INFO 11-19 07:05:28 engine.py:290] Added request chat-904c8657d7ad42e9b3549325a4ff3758.
INFO 11-19 07:05:28 engine.py:290] Added request chat-257f5e1c611c4e27b9a424f50fa5cdb6.
INFO 11-19 07:05:28 engine.py:290] Added request chat-ef1db9fa5cf34a4994a56d59f559fa8d.
INFO 11-19 07:05:28 engine.py:290] Added request chat-7a1fe48da8454801a8d47807490e0f07.
INFO 11-19 07:05:28 engine.py:290] Added request chat-aa484b2bed4945aa97a260780eee1380.
INFO 11-19 07:05:28 engine.py:290] Added request chat-ae5ca99db8e844409f5f70776182b3c4.
INFO 11-19 07:05:28 engine.py:290] Added request chat-f5cf657361c14c2fb5b24537ce9f9cc7.
INFO 11-19 07:05:28 engine.py:290] Added request chat-8008efbf51a84132bb61f8b0b0aee4dd.
INFO 11-19 07:05:29 metrics.py:349] Avg prompt throughput: 5778.1 tokens/s, Avg generation throughput: 11.0 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:29 logger.py:37] Received request chat-84ec4394873c483f961ca5fc56d39da5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-510e525c05f74786bc12b94dc6d56472: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 engine.py:290] Added request chat-84ec4394873c483f961ca5fc56d39da5.
INFO 11-19 07:05:29 logger.py:37] Received request chat-18b4cade070f4e0db2cfbc41b80f46d7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-76328515665e489c8a7f19359675ade4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-634341174981420e8eb893fa29476362: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-af960fada8124af8af49faca9f712fe9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-d77ba912500746e0900fca820138c222: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-09a9aaf1095b4eee9a029623b73899c3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-efda2fa50c804034bbed265d8975c000: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 logger.py:37] Received request chat-cd42d56f68b34b0bb14dbbdfd38b3524: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:29 engine.py:290] Added request chat-510e525c05f74786bc12b94dc6d56472.
INFO 11-19 07:05:29 engine.py:290] Added request chat-18b4cade070f4e0db2cfbc41b80f46d7.
INFO 11-19 07:05:29 engine.py:290] Added request chat-76328515665e489c8a7f19359675ade4.
INFO 11-19 07:05:29 engine.py:290] Added request chat-634341174981420e8eb893fa29476362.
INFO 11-19 07:05:29 engine.py:290] Added request chat-af960fada8124af8af49faca9f712fe9.
INFO 11-19 07:05:29 engine.py:290] Added request chat-d77ba912500746e0900fca820138c222.
INFO 11-19 07:05:29 engine.py:290] Added request chat-09a9aaf1095b4eee9a029623b73899c3.
INFO 11-19 07:05:29 engine.py:290] Added request chat-efda2fa50c804034bbed265d8975c000.
INFO 11-19 07:05:29 engine.py:290] Added request chat-cd42d56f68b34b0bb14dbbdfd38b3524.
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:30 logger.py:37] Received request chat-81284f91bdd043c79b8e6b67d91d2f65: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 engine.py:290] Added request chat-81284f91bdd043c79b8e6b67d91d2f65.
INFO 11-19 07:05:30 logger.py:37] Received request chat-c8e453a9795f427ca73ba17b4812fcd0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-1573e7f128e6458bbb2f343d3c216135: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-1dedc838f44a4dafbb925c5403fd1bea: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-3492e2865fb4458784e300bf960a9ab7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-a3c93693e72c48a08304a91cdddac96b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-dbfce2220cae4096835033221cf4e267: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-14a9f668886b42a9bbbf62e40eb29560: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-e1f608567eed4ce4b688715126aac6df: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 logger.py:37] Received request chat-e7f9eb3013d54fdcab4ccc1ddcf1e6ea: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:30 engine.py:290] Added request chat-c8e453a9795f427ca73ba17b4812fcd0.
INFO 11-19 07:05:30 engine.py:290] Added request chat-1573e7f128e6458bbb2f343d3c216135.
INFO 11-19 07:05:30 engine.py:290] Added request chat-1dedc838f44a4dafbb925c5403fd1bea.
INFO 11-19 07:05:30 engine.py:290] Added request chat-3492e2865fb4458784e300bf960a9ab7.
INFO 11-19 07:05:30 engine.py:290] Added request chat-a3c93693e72c48a08304a91cdddac96b.
INFO 11-19 07:05:30 engine.py:290] Added request chat-dbfce2220cae4096835033221cf4e267.
INFO 11-19 07:05:30 engine.py:290] Added request chat-14a9f668886b42a9bbbf62e40eb29560.
INFO 11-19 07:05:30 engine.py:290] Added request chat-e1f608567eed4ce4b688715126aac6df.
INFO 11-19 07:05:30 engine.py:290] Added request chat-e7f9eb3013d54fdcab4ccc1ddcf1e6ea.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:31 logger.py:37] Received request chat-f6cf836b8c91427286527cad7ff0cc56: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 engine.py:290] Added request chat-f6cf836b8c91427286527cad7ff0cc56.
INFO 11-19 07:05:31 logger.py:37] Received request chat-da1ad8437d6b494cb9f74f0bac493a7c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-d3ece406f06a4af199f8ecf75762a7ea: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-0be1c8cdf18544389112cdae3848c812: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-03d4651d4a9e49ceb4ce3ba3e9928c1a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-0b8c6fdee8a148c99856f12ed69b7968: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-1adb30ec9a014c6dac6c5055ca6a12ec: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-a0b3418d6b6947b1b1f6ef0a769f8fb2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-4d842ba0c8ca4f32bfda77b987b7e4d1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 logger.py:37] Received request chat-060b1b7dcc774eadbd21fe4abb62a3d7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:31 engine.py:290] Added request chat-da1ad8437d6b494cb9f74f0bac493a7c.
INFO 11-19 07:05:31 engine.py:290] Added request chat-d3ece406f06a4af199f8ecf75762a7ea.
INFO 11-19 07:05:31 engine.py:290] Added request chat-0be1c8cdf18544389112cdae3848c812.
INFO 11-19 07:05:31 engine.py:290] Added request chat-03d4651d4a9e49ceb4ce3ba3e9928c1a.
INFO 11-19 07:05:31 engine.py:290] Added request chat-0b8c6fdee8a148c99856f12ed69b7968.
INFO 11-19 07:05:31 engine.py:290] Added request chat-1adb30ec9a014c6dac6c5055ca6a12ec.
INFO 11-19 07:05:31 engine.py:290] Added request chat-a0b3418d6b6947b1b1f6ef0a769f8fb2.
INFO 11-19 07:05:31 engine.py:290] Added request chat-4d842ba0c8ca4f32bfda77b987b7e4d1.
INFO 11-19 07:05:31 engine.py:290] Added request chat-060b1b7dcc774eadbd21fe4abb62a3d7.
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:32 logger.py:37] Received request chat-42ab4eb6b9cd484981a6644f072a664a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-7a9c08a4d2d8454d89b948bca4f63d7a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 engine.py:290] Added request chat-42ab4eb6b9cd484981a6644f072a664a.
INFO 11-19 07:05:32 logger.py:37] Received request chat-f1cb60e4d9044b638ffabdf2085de481: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-ffbdf58633dd4d5c8e1fee0b42643178: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-8346a6a192c64e77958c56f3dc200cb9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-5f04a997116b4406a4c8de5ecc25b6b1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-6d4fef9ba6a047bd94eb77bb6562578d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-3efb4a958d8e418599cd3dd3d1bc1cec: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-35139bdbc60d49cdb098a2095561e37b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:32 logger.py:37] Received request chat-ced71006c7a74ef5945d8310ddd57727: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:33 engine.py:290] Added request chat-7a9c08a4d2d8454d89b948bca4f63d7a.
INFO 11-19 07:05:33 engine.py:290] Added request chat-f1cb60e4d9044b638ffabdf2085de481.
INFO 11-19 07:05:33 engine.py:290] Added request chat-ffbdf58633dd4d5c8e1fee0b42643178.
INFO 11-19 07:05:33 engine.py:290] Added request chat-8346a6a192c64e77958c56f3dc200cb9.
INFO 11-19 07:05:33 engine.py:290] Added request chat-5f04a997116b4406a4c8de5ecc25b6b1.
INFO 11-19 07:05:33 engine.py:290] Added request chat-6d4fef9ba6a047bd94eb77bb6562578d.
INFO 11-19 07:05:33 engine.py:290] Added request chat-3efb4a958d8e418599cd3dd3d1bc1cec.
INFO 11-19 07:05:33 engine.py:290] Added request chat-35139bdbc60d49cdb098a2095561e37b.
INFO 11-19 07:05:33 engine.py:290] Added request chat-ced71006c7a74ef5945d8310ddd57727.
INFO 11-19 07:05:34 metrics.py:349] Avg prompt throughput: 15121.5 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:34 logger.py:37] Received request chat-237e9463ffab4502b5b35e3bb7e147e0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-6c4f800a223141f0b8df32379d508c94: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 engine.py:290] Added request chat-237e9463ffab4502b5b35e3bb7e147e0.
INFO 11-19 07:05:34 logger.py:37] Received request chat-108c979ab7094ac1908674355d7b773c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-c77849f9ab8c4d8ab65d4809c8cf6d78: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-003e47c42e2b41e6ac46bf07bfd1e3c6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-6cae44a19556482886c75b19f87925ff: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-80791607a87449578359cba118bfec2e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-de6ee981a7804130b91e3b628f40e331: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-64945d5eef564c4195907ff2e4e87bd4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 logger.py:37] Received request chat-fc684ee1a8284cafba16c696ac868222: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:34 engine.py:290] Added request chat-6c4f800a223141f0b8df32379d508c94.
INFO 11-19 07:05:34 engine.py:290] Added request chat-108c979ab7094ac1908674355d7b773c.
INFO 11-19 07:05:34 engine.py:290] Added request chat-c77849f9ab8c4d8ab65d4809c8cf6d78.
INFO 11-19 07:05:34 engine.py:290] Added request chat-003e47c42e2b41e6ac46bf07bfd1e3c6.
INFO 11-19 07:05:34 engine.py:290] Added request chat-6cae44a19556482886c75b19f87925ff.
INFO 11-19 07:05:34 engine.py:290] Added request chat-80791607a87449578359cba118bfec2e.
INFO 11-19 07:05:34 engine.py:290] Added request chat-de6ee981a7804130b91e3b628f40e331.
INFO 11-19 07:05:34 engine.py:290] Added request chat-64945d5eef564c4195907ff2e4e87bd4.
INFO 11-19 07:05:34 engine.py:290] Added request chat-fc684ee1a8284cafba16c696ac868222.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:35 logger.py:37] Received request chat-f5de86c13be34c4dae79252cdee78ddf: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 engine.py:290] Added request chat-f5de86c13be34c4dae79252cdee78ddf.
INFO 11-19 07:05:35 logger.py:37] Received request chat-29c8f98ca18d4d13acf592fc81e12a85: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-1ae4b1da8f7f4edfa9a54c59f9ad4767: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-ab10dae1d67841b3a0c2e363217d191d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-7b23384c8eed49b18055d271499a1819: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-bfeda02ad530480d88355f72bb5246fd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-dc737cb6eb374c11b86b9150483833d6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-5891ec0e17e14401b23fcac3945cd8d4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-927d70cbe0fe481a843ff061ed4ee358: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 logger.py:37] Received request chat-8aa4597af5024b578e2d20d1d53a6799: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:35 engine.py:290] Added request chat-29c8f98ca18d4d13acf592fc81e12a85.
INFO 11-19 07:05:35 engine.py:290] Added request chat-1ae4b1da8f7f4edfa9a54c59f9ad4767.
INFO 11-19 07:05:35 engine.py:290] Added request chat-ab10dae1d67841b3a0c2e363217d191d.
INFO 11-19 07:05:35 engine.py:290] Added request chat-7b23384c8eed49b18055d271499a1819.
INFO 11-19 07:05:35 engine.py:290] Added request chat-bfeda02ad530480d88355f72bb5246fd.
INFO 11-19 07:05:35 engine.py:290] Added request chat-dc737cb6eb374c11b86b9150483833d6.
INFO 11-19 07:05:35 engine.py:290] Added request chat-5891ec0e17e14401b23fcac3945cd8d4.
INFO 11-19 07:05:35 engine.py:290] Added request chat-927d70cbe0fe481a843ff061ed4ee358.
INFO 11-19 07:05:35 engine.py:290] Added request chat-8aa4597af5024b578e2d20d1d53a6799.
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:36 logger.py:37] Received request chat-79c979432d524bd48f56ae65025a3e1d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-93eb1ae600744542bb9cded8c6f5d30d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 engine.py:290] Added request chat-79c979432d524bd48f56ae65025a3e1d.
INFO 11-19 07:05:36 engine.py:290] Added request chat-93eb1ae600744542bb9cded8c6f5d30d.
INFO 11-19 07:05:36 logger.py:37] Received request chat-9802b4233ab44f198dc8cb9fb252d25e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-092de9105abd41a6a20826f8dc0ad62a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-a01da05832474393acf0d32d271c3e23: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-bda67cb4e4c04350b4fa7f38e9ca1354: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-210b6ad014184e5c8cbd2603abf580be: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-4bd3743cf62d4786b094ca54d86f3efb: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-288423f0460243ba95f911bb8ecd99ef: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 logger.py:37] Received request chat-626951d8d0e945d0851eece90bbb6594: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:36 engine.py:290] Added request chat-9802b4233ab44f198dc8cb9fb252d25e.
INFO 11-19 07:05:36 engine.py:290] Added request chat-092de9105abd41a6a20826f8dc0ad62a.
INFO 11-19 07:05:36 engine.py:290] Added request chat-a01da05832474393acf0d32d271c3e23.
INFO 11-19 07:05:36 engine.py:290] Added request chat-bda67cb4e4c04350b4fa7f38e9ca1354.
INFO 11-19 07:05:36 engine.py:290] Added request chat-210b6ad014184e5c8cbd2603abf580be.
INFO 11-19 07:05:36 engine.py:290] Added request chat-4bd3743cf62d4786b094ca54d86f3efb.
INFO 11-19 07:05:36 engine.py:290] Added request chat-288423f0460243ba95f911bb8ecd99ef.
INFO 11-19 07:05:36 engine.py:290] Added request chat-626951d8d0e945d0851eece90bbb6594.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:37 logger.py:37] Received request chat-39a6e0910c8a4c2da5cab20c749dcfed: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 logger.py:37] Received request chat-ab374404750b4a59b3c3b8f7bd4a3b68: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 engine.py:290] Added request chat-39a6e0910c8a4c2da5cab20c749dcfed.
INFO 11-19 07:05:37 logger.py:37] Received request chat-6248c9e16bd94da9901f71589896055f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 engine.py:290] Added request chat-ab374404750b4a59b3c3b8f7bd4a3b68.
INFO 11-19 07:05:37 logger.py:37] Received request chat-f8a052d2560241b59b8c4e2d8432e56a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 logger.py:37] Received request chat-8196a6c047ce4e2390d03cd0803e4bf6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 logger.py:37] Received request chat-ef8c8eb031384b2eb6f66b0c8d3460bd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 logger.py:37] Received request chat-d470857acf7e445a9911c10239d5a485: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 logger.py:37] Received request chat-e78c539cfbd744b79fdcff23090cacf9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 logger.py:37] Received request chat-fd62af6a2c504177a2c93c20faa65c61: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 logger.py:37] Received request chat-f049d163e2d94f6ab12fb8a599768abe: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:37 engine.py:290] Added request chat-6248c9e16bd94da9901f71589896055f.
INFO 11-19 07:05:37 engine.py:290] Added request chat-f8a052d2560241b59b8c4e2d8432e56a.
INFO 11-19 07:05:37 engine.py:290] Added request chat-8196a6c047ce4e2390d03cd0803e4bf6.
INFO 11-19 07:05:37 engine.py:290] Added request chat-ef8c8eb031384b2eb6f66b0c8d3460bd.
INFO 11-19 07:05:37 engine.py:290] Added request chat-d470857acf7e445a9911c10239d5a485.
INFO 11-19 07:05:37 engine.py:290] Added request chat-e78c539cfbd744b79fdcff23090cacf9.
INFO 11-19 07:05:37 engine.py:290] Added request chat-fd62af6a2c504177a2c93c20faa65c61.
INFO 11-19 07:05:37 engine.py:290] Added request chat-f049d163e2d94f6ab12fb8a599768abe.
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:38 logger.py:37] Received request chat-99a532753069474f80c7cce8ff10655b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 engine.py:290] Added request chat-99a532753069474f80c7cce8ff10655b.
INFO 11-19 07:05:38 logger.py:37] Received request chat-270e1ede7b704ba7a069b882602b3221: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-f57fd615cba34a1db061f14b12b35cbf: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-aefaee63275a4b0b8a1d89c2f0bc037e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-74b33f42c1fb4d99b6a4a6f31aca3b14: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-8584888da82e4e14b51d466e0b4b170e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-dffffb76c4374e30b055576b340a7c33: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-b5b5b07c51d4405294687362d04212eb: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-b102825b7a1c404c9652a5774dead614: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:38 logger.py:37] Received request chat-6b66f78c3b5a4f8ead9a543d2de93fb9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:39 engine.py:290] Added request chat-270e1ede7b704ba7a069b882602b3221.
INFO 11-19 07:05:39 engine.py:290] Added request chat-f57fd615cba34a1db061f14b12b35cbf.
INFO 11-19 07:05:39 engine.py:290] Added request chat-aefaee63275a4b0b8a1d89c2f0bc037e.
INFO 11-19 07:05:39 engine.py:290] Added request chat-74b33f42c1fb4d99b6a4a6f31aca3b14.
INFO 11-19 07:05:39 engine.py:290] Added request chat-8584888da82e4e14b51d466e0b4b170e.
INFO 11-19 07:05:39 engine.py:290] Added request chat-dffffb76c4374e30b055576b340a7c33.
INFO 11-19 07:05:39 engine.py:290] Added request chat-b5b5b07c51d4405294687362d04212eb.
INFO 11-19 07:05:39 engine.py:290] Added request chat-b102825b7a1c404c9652a5774dead614.
INFO 11-19 07:05:39 engine.py:290] Added request chat-6b66f78c3b5a4f8ead9a543d2de93fb9.
INFO 11-19 07:05:39 metrics.py:349] Avg prompt throughput: 14165.4 tokens/s, Avg generation throughput: 47.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 7 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:40 logger.py:37] Received request chat-121651a3b3304484be4438bd8a423ba1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 engine.py:290] Added request chat-121651a3b3304484be4438bd8a423ba1.
INFO 11-19 07:05:40 logger.py:37] Received request chat-a6636157a42c4ffa97f5d4bff012f649: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-164cdcfc5d7141b4be6dc103712d9e5a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-6ba11dd052ad432f902146e62a0d40d8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-9665d63a1b87471b8604c08418126b4b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-43fd61d247ec46ff96c5a2a052f3cbde: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-e6a90dc7ed7a45b6a14baa45ef6f227a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-4cf5203870504b56b85d80c349876c18: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-cca01fd60f724c3ea3b5d699a5ca806f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 logger.py:37] Received request chat-59b9d03a372747b09d1515e39df27792: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:40 engine.py:290] Added request chat-a6636157a42c4ffa97f5d4bff012f649.
INFO 11-19 07:05:40 engine.py:290] Added request chat-164cdcfc5d7141b4be6dc103712d9e5a.
INFO 11-19 07:05:40 engine.py:290] Added request chat-6ba11dd052ad432f902146e62a0d40d8.
INFO 11-19 07:05:40 engine.py:290] Added request chat-9665d63a1b87471b8604c08418126b4b.
INFO 11-19 07:05:40 engine.py:290] Added request chat-43fd61d247ec46ff96c5a2a052f3cbde.
INFO 11-19 07:05:40 engine.py:290] Added request chat-e6a90dc7ed7a45b6a14baa45ef6f227a.
INFO 11-19 07:05:40 engine.py:290] Added request chat-4cf5203870504b56b85d80c349876c18.
INFO 11-19 07:05:40 engine.py:290] Added request chat-cca01fd60f724c3ea3b5d699a5ca806f.
INFO 11-19 07:05:40 engine.py:290] Added request chat-59b9d03a372747b09d1515e39df27792.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:41 logger.py:37] Received request chat-4c6bf289f7b14b86b39f47867fcf7b10: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 engine.py:290] Added request chat-4c6bf289f7b14b86b39f47867fcf7b10.
INFO 11-19 07:05:41 logger.py:37] Received request chat-1eefc88e90ce4d179e617898f6031010: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-7f98d694e2534241a7a9ff1de40234a4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-e0705656dc7b4548bb46cc37cd7b105b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-fcf3a28a05d5431faf9060bb25fa7a69: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-7429dca49762441da41cad9537d5ae8f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-fb76daa781344485b7738859df9bda15: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-84f3213aaaec437eb3c5dff02285b0b4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-5d316634e6d247d8909764cba5553b5d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 logger.py:37] Received request chat-c7b89be734924ce08a5bd5535417d08a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:41 engine.py:290] Added request chat-1eefc88e90ce4d179e617898f6031010.
INFO 11-19 07:05:41 engine.py:290] Added request chat-7f98d694e2534241a7a9ff1de40234a4.
INFO 11-19 07:05:41 engine.py:290] Added request chat-e0705656dc7b4548bb46cc37cd7b105b.
INFO 11-19 07:05:41 engine.py:290] Added request chat-fcf3a28a05d5431faf9060bb25fa7a69.
INFO 11-19 07:05:41 engine.py:290] Added request chat-7429dca49762441da41cad9537d5ae8f.
INFO 11-19 07:05:41 engine.py:290] Added request chat-fb76daa781344485b7738859df9bda15.
INFO 11-19 07:05:41 engine.py:290] Added request chat-84f3213aaaec437eb3c5dff02285b0b4.
INFO 11-19 07:05:41 engine.py:290] Added request chat-5d316634e6d247d8909764cba5553b5d.
INFO 11-19 07:05:41 engine.py:290] Added request chat-c7b89be734924ce08a5bd5535417d08a.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:42 logger.py:37] Received request chat-b966b6156b0e4350956bb9dd9a4c7816: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 engine.py:290] Added request chat-b966b6156b0e4350956bb9dd9a4c7816.
INFO 11-19 07:05:42 logger.py:37] Received request chat-f8cf696d4edc41ee9fdb69691b6342e3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-a677e9b7ec4547cdaa168a6fa2bc11d9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-2bea97ffea2e43d8acc602d2111cae3b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-b628c02eea954181b9919698e1cbe673: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-45a52ac5d38c49c0ab50fda3d35b314c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-7b968652df8a45edbb7b51749a39a764: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-168db00aecd34700978881b2d70d1bc6: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-0a666ff37ba54df482a4198cfa3472cd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 logger.py:37] Received request chat-243f0b027b19489d882c8fa071fd4538: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:42 engine.py:290] Added request chat-f8cf696d4edc41ee9fdb69691b6342e3.
INFO 11-19 07:05:42 engine.py:290] Added request chat-a677e9b7ec4547cdaa168a6fa2bc11d9.
INFO 11-19 07:05:42 engine.py:290] Added request chat-2bea97ffea2e43d8acc602d2111cae3b.
INFO 11-19 07:05:42 engine.py:290] Added request chat-b628c02eea954181b9919698e1cbe673.
INFO 11-19 07:05:42 engine.py:290] Added request chat-45a52ac5d38c49c0ab50fda3d35b314c.
INFO 11-19 07:05:42 engine.py:290] Added request chat-7b968652df8a45edbb7b51749a39a764.
INFO 11-19 07:05:42 engine.py:290] Added request chat-168db00aecd34700978881b2d70d1bc6.
INFO 11-19 07:05:42 engine.py:290] Added request chat-0a666ff37ba54df482a4198cfa3472cd.
INFO 11-19 07:05:42 engine.py:290] Added request chat-243f0b027b19489d882c8fa071fd4538.
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:43 logger.py:37] Received request chat-b6a4654b78d142a99a414eb7512397ac: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 engine.py:290] Added request chat-b6a4654b78d142a99a414eb7512397ac.
INFO 11-19 07:05:43 logger.py:37] Received request chat-d4180e89b18d41559a873c51986ea140: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-e21515744f82416ab24ab78ef854f92d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-2349be90b5b747bd9c190941649891ab: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-8161a67517d84c3cb685a4e7438f6942: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-369d62dc45c74f6f962bc3093c60cc21: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-50ae9ae3670e416b9c81e1f9a45e499a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-cd86c22d688741b28662f5f4e5d65b7d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-0eeebacdee3944fc9497977249dca5a1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 logger.py:37] Received request chat-bfa1d3379fb74f1e9692d13a1be96e93: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:43 engine.py:290] Added request chat-d4180e89b18d41559a873c51986ea140.
INFO 11-19 07:05:43 engine.py:290] Added request chat-e21515744f82416ab24ab78ef854f92d.
INFO 11-19 07:05:43 engine.py:290] Added request chat-2349be90b5b747bd9c190941649891ab.
INFO 11-19 07:05:43 engine.py:290] Added request chat-8161a67517d84c3cb685a4e7438f6942.
INFO 11-19 07:05:43 engine.py:290] Added request chat-369d62dc45c74f6f962bc3093c60cc21.
INFO 11-19 07:05:43 engine.py:290] Added request chat-50ae9ae3670e416b9c81e1f9a45e499a.
INFO 11-19 07:05:43 engine.py:290] Added request chat-cd86c22d688741b28662f5f4e5d65b7d.
INFO 11-19 07:05:43 engine.py:290] Added request chat-0eeebacdee3944fc9497977249dca5a1.
INFO 11-19 07:05:43 engine.py:290] Added request chat-bfa1d3379fb74f1e9692d13a1be96e93.
INFO 11-19 07:05:44 metrics.py:349] Avg prompt throughput: 14696.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 5 reqs, Swapped: 0 reqs, Pending: 5 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:44 logger.py:37] Received request chat-cb718ba859664e759169828eae9c2b3f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:44 engine.py:290] Added request chat-cb718ba859664e759169828eae9c2b3f.
INFO 11-19 07:05:44 logger.py:37] Received request chat-1c905a3358f748af8d9d46a58961c0e1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:44 logger.py:37] Received request chat-bd492bdc23e34ccda6a42e06eb061c69: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:44 logger.py:37] Received request chat-6f5bad5bcd8043a2ab64b4adaada94bc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:44 logger.py:37] Received request chat-bad8c88cb7814e5ebe773106529a7b64: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:44 logger.py:37] Received request chat-c53ef933c5894a4c92d2492af8c0c345: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:44 logger.py:37] Received request chat-c75583c15cd14bf09eeaf8616e9a916b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:45 logger.py:37] Received request chat-a79e593d90554c80aae3e4ebe69d8df4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:45 logger.py:37] Received request chat-a5644bd7e5da4a87bcb462d3dc395b2d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:45 logger.py:37] Received request chat-1644c9fa622d4f118ab9969736b552cf: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:45 engine.py:290] Added request chat-1c905a3358f748af8d9d46a58961c0e1.
INFO 11-19 07:05:45 engine.py:290] Added request chat-bd492bdc23e34ccda6a42e06eb061c69.
INFO 11-19 07:05:45 engine.py:290] Added request chat-6f5bad5bcd8043a2ab64b4adaada94bc.
INFO 11-19 07:05:45 engine.py:290] Added request chat-bad8c88cb7814e5ebe773106529a7b64.
INFO 11-19 07:05:45 engine.py:290] Added request chat-c53ef933c5894a4c92d2492af8c0c345.
INFO 11-19 07:05:45 engine.py:290] Added request chat-c75583c15cd14bf09eeaf8616e9a916b.
INFO 11-19 07:05:45 engine.py:290] Added request chat-a79e593d90554c80aae3e4ebe69d8df4.
INFO 11-19 07:05:45 engine.py:290] Added request chat-a5644bd7e5da4a87bcb462d3dc395b2d.
INFO 11-19 07:05:45 engine.py:290] Added request chat-1644c9fa622d4f118ab9969736b552cf.
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:46 logger.py:37] Received request chat-2e4a575cda514a229b8f4e23955b8564: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 engine.py:290] Added request chat-2e4a575cda514a229b8f4e23955b8564.
INFO 11-19 07:05:46 logger.py:37] Received request chat-181805772d834d84946122f23c8034fd: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-e308e1cffab445249c6536201bdcf127: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-4b7793d38d10454a8cb669b43878dd79: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-3118ce894040480bba5bdcae81e2d395: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-3a31d947b8ab4429a69607ac150deb47: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-c366d8255f1243b180ba94ba9ae82e7c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-fdaff262165d4f29bedf518263d2ccfe: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-ae9b2b098d5f45ab857eeef20a44eba4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 logger.py:37] Received request chat-89bc37f0d09a4e02bcd44366d278397f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:46 engine.py:290] Added request chat-181805772d834d84946122f23c8034fd.
INFO 11-19 07:05:46 engine.py:290] Added request chat-e308e1cffab445249c6536201bdcf127.
INFO 11-19 07:05:46 engine.py:290] Added request chat-4b7793d38d10454a8cb669b43878dd79.
INFO 11-19 07:05:46 engine.py:290] Added request chat-3118ce894040480bba5bdcae81e2d395.
INFO 11-19 07:05:46 engine.py:290] Added request chat-3a31d947b8ab4429a69607ac150deb47.
INFO 11-19 07:05:46 engine.py:290] Added request chat-c366d8255f1243b180ba94ba9ae82e7c.
INFO 11-19 07:05:46 engine.py:290] Added request chat-fdaff262165d4f29bedf518263d2ccfe.
INFO 11-19 07:05:46 engine.py:290] Added request chat-ae9b2b098d5f45ab857eeef20a44eba4.
INFO 11-19 07:05:46 engine.py:290] Added request chat-89bc37f0d09a4e02bcd44366d278397f.
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:47 logger.py:37] Received request chat-f9042a8020d949a4ade3ab383a65e043: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-4e1b9451c2ad425fbace9e4290d0a0e7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 engine.py:290] Added request chat-f9042a8020d949a4ade3ab383a65e043.
INFO 11-19 07:05:47 engine.py:290] Added request chat-4e1b9451c2ad425fbace9e4290d0a0e7.
INFO 11-19 07:05:47 logger.py:37] Received request chat-6fb92abe408a476e8ccb9f47d64c0d40: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-3aece9f8cd3e4990ba511e75ba179b21: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-9bd887086db24bca93cdb9ad01705e42: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-4a36bd552c354ca0b252e3b12ebb0318: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-a4f399be39184293b18e8d2dfc6542d3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-ca25549a3f8f48f487aa6caf200be5d0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-8f94ed8596e44aa6813ba9843cd1be83: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 logger.py:37] Received request chat-e46703bb8b824033ab8b4f508e5cafa1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:47 engine.py:290] Added request chat-6fb92abe408a476e8ccb9f47d64c0d40.
INFO 11-19 07:05:47 engine.py:290] Added request chat-3aece9f8cd3e4990ba511e75ba179b21.
INFO 11-19 07:05:47 engine.py:290] Added request chat-9bd887086db24bca93cdb9ad01705e42.
INFO 11-19 07:05:47 engine.py:290] Added request chat-4a36bd552c354ca0b252e3b12ebb0318.
INFO 11-19 07:05:47 engine.py:290] Added request chat-a4f399be39184293b18e8d2dfc6542d3.
INFO 11-19 07:05:47 engine.py:290] Added request chat-ca25549a3f8f48f487aa6caf200be5d0.
INFO 11-19 07:05:47 engine.py:290] Added request chat-8f94ed8596e44aa6813ba9843cd1be83.
INFO 11-19 07:05:47 engine.py:290] Added request chat-e46703bb8b824033ab8b4f508e5cafa1.
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:48 logger.py:37] Received request chat-0f6d727934dc48918f89d99d23d05e80: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 engine.py:290] Added request chat-0f6d727934dc48918f89d99d23d05e80.
INFO 11-19 07:05:48 logger.py:37] Received request chat-a5fe9320d6374bba9a8e7f0cfdab7303: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-9e685a93de7e465eb2a96a129407ca32: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-01787e1737c247b4a7996d4c1e39bd9b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-196915cb41cd4e089c2194753ac1c6ca: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-41558e08bc8f42d09b27c4464a9d8a16: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-c85a174fd0f14b9fa9b8331a24890cf7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-2587371d2d184cb2834c2a0afa0afbff: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-a8064bd7fb034d93bb772d375464ab07: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 logger.py:37] Received request chat-c0dd9c3af3404d77a160ee6086b51bfb: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:48 engine.py:290] Added request chat-a5fe9320d6374bba9a8e7f0cfdab7303.
INFO 11-19 07:05:48 engine.py:290] Added request chat-9e685a93de7e465eb2a96a129407ca32.
INFO 11-19 07:05:48 engine.py:290] Added request chat-01787e1737c247b4a7996d4c1e39bd9b.
INFO 11-19 07:05:48 engine.py:290] Added request chat-196915cb41cd4e089c2194753ac1c6ca.
INFO 11-19 07:05:48 engine.py:290] Added request chat-41558e08bc8f42d09b27c4464a9d8a16.
INFO 11-19 07:05:48 engine.py:290] Added request chat-c85a174fd0f14b9fa9b8331a24890cf7.
INFO 11-19 07:05:48 engine.py:290] Added request chat-2587371d2d184cb2834c2a0afa0afbff.
INFO 11-19 07:05:48 engine.py:290] Added request chat-a8064bd7fb034d93bb772d375464ab07.
INFO 11-19 07:05:48 engine.py:290] Added request chat-c0dd9c3af3404d77a160ee6086b51bfb.
INFO 11-19 07:05:49 metrics.py:349] Avg prompt throughput: 14797.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 7 reqs, Swapped: 0 reqs, Pending: 3 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:49 logger.py:37] Received request chat-2749a969319c46db8c515b69f59de894: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 engine.py:290] Added request chat-2749a969319c46db8c515b69f59de894.
INFO 11-19 07:05:49 logger.py:37] Received request chat-7bab8f821f5c48c78102282cb302682d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-b2dd5be3e23d477589a6039b6ab281cc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-e4275959412543a6a24bb9eeef724f72: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-b7bcc405c95e44ad9db405d88550d56b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-70c97011c35a41d5856a68d6026f71c0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-2d335c3776114990ba38428489b9246b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-1c482bbcbd80406996e43a0e80d72d25: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-b4efe7c3e9a643b4a096ac1991463c96: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 logger.py:37] Received request chat-d278f6f865d54bb2b5d52a8e0e93ef77: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:49 engine.py:290] Added request chat-7bab8f821f5c48c78102282cb302682d.
INFO 11-19 07:05:49 engine.py:290] Added request chat-b2dd5be3e23d477589a6039b6ab281cc.
INFO 11-19 07:05:49 engine.py:290] Added request chat-e4275959412543a6a24bb9eeef724f72.
INFO 11-19 07:05:49 engine.py:290] Added request chat-b7bcc405c95e44ad9db405d88550d56b.
INFO 11-19 07:05:49 engine.py:290] Added request chat-70c97011c35a41d5856a68d6026f71c0.
INFO 11-19 07:05:49 engine.py:290] Added request chat-2d335c3776114990ba38428489b9246b.
INFO 11-19 07:05:49 engine.py:290] Added request chat-1c482bbcbd80406996e43a0e80d72d25.
INFO 11-19 07:05:49 engine.py:290] Added request chat-b4efe7c3e9a643b4a096ac1991463c96.
INFO 11-19 07:05:49 engine.py:290] Added request chat-d278f6f865d54bb2b5d52a8e0e93ef77.
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:50 logger.py:37] Received request chat-d47c63535eff44ceab5085ce6d3b0420: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:50 engine.py:290] Added request chat-d47c63535eff44ceab5085ce6d3b0420.
INFO 11-19 07:05:50 logger.py:37] Received request chat-975ef3abb82a49b9b02dcf18b9e60f12: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:50 logger.py:37] Received request chat-5d29604da120428686a214dbbcb8586f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 logger.py:37] Received request chat-4d33c51f10c34eb4a1630162d13d1932: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 logger.py:37] Received request chat-ef234426dacf40d3a0327e99488fbe4c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 logger.py:37] Received request chat-20da5e2c35294c4298662f8d40d898c5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 logger.py:37] Received request chat-4e0f97dbdab14f279ea26ae8c2c943e9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 logger.py:37] Received request chat-2259c4ccc0e445b499c08dcb33d0746b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 logger.py:37] Received request chat-6530291f289b40229102ff2b58292184: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 logger.py:37] Received request chat-4a2f28d3e1f84b60bdec0398f16d49cc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:51 engine.py:290] Added request chat-975ef3abb82a49b9b02dcf18b9e60f12.
INFO 11-19 07:05:51 engine.py:290] Added request chat-5d29604da120428686a214dbbcb8586f.
INFO 11-19 07:05:51 engine.py:290] Added request chat-4d33c51f10c34eb4a1630162d13d1932.
INFO 11-19 07:05:51 engine.py:290] Added request chat-ef234426dacf40d3a0327e99488fbe4c.
INFO 11-19 07:05:51 engine.py:290] Added request chat-20da5e2c35294c4298662f8d40d898c5.
INFO 11-19 07:05:51 engine.py:290] Added request chat-4e0f97dbdab14f279ea26ae8c2c943e9.
INFO 11-19 07:05:51 engine.py:290] Added request chat-2259c4ccc0e445b499c08dcb33d0746b.
INFO 11-19 07:05:51 engine.py:290] Added request chat-6530291f289b40229102ff2b58292184.
INFO 11-19 07:05:51 engine.py:290] Added request chat-4a2f28d3e1f84b60bdec0398f16d49cc.
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:52 logger.py:37] Received request chat-40be5bfaea454667ac1d199b9a4210ff: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 engine.py:290] Added request chat-40be5bfaea454667ac1d199b9a4210ff.
INFO 11-19 07:05:52 logger.py:37] Received request chat-dd5f8026761b4caea36e5893bc16ee93: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-bc3d63e044c946d0983a7b433cb97014: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-ecba44d593cd48dbaedca3950beaac79: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-89d7d31b6b334d578133150911ce910c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-0c3eb8d99d144d81b57e5eb749206a05: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-8fa5c3e16a494c21a39f6f3e41517af0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-cc2bc55dce5443b1ad54776fae8d1856: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-6b3626b463844c39b25ae074d4a44fbe: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 logger.py:37] Received request chat-037cc42cff13462f9f65a3b950a5b78c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:52 engine.py:290] Added request chat-dd5f8026761b4caea36e5893bc16ee93.
INFO 11-19 07:05:52 engine.py:290] Added request chat-bc3d63e044c946d0983a7b433cb97014.
INFO 11-19 07:05:52 engine.py:290] Added request chat-ecba44d593cd48dbaedca3950beaac79.
INFO 11-19 07:05:52 engine.py:290] Added request chat-89d7d31b6b334d578133150911ce910c.
INFO 11-19 07:05:52 engine.py:290] Added request chat-0c3eb8d99d144d81b57e5eb749206a05.
INFO 11-19 07:05:52 engine.py:290] Added request chat-8fa5c3e16a494c21a39f6f3e41517af0.
INFO 11-19 07:05:52 engine.py:290] Added request chat-cc2bc55dce5443b1ad54776fae8d1856.
INFO 11-19 07:05:52 engine.py:290] Added request chat-6b3626b463844c39b25ae074d4a44fbe.
INFO 11-19 07:05:52 engine.py:290] Added request chat-037cc42cff13462f9f65a3b950a5b78c.
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:53 logger.py:37] Received request chat-812c5f98ef1144f19fda174d76069fc5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 engine.py:290] Added request chat-812c5f98ef1144f19fda174d76069fc5.
INFO 11-19 07:05:53 logger.py:37] Received request chat-026dc29e011547f58462e1d3c7e023a8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-72e84c9a527e4e4a99a084969cef4c57: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-23387c373aba4ae0a641389b5abeefa7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-305916b90d0042ecba9fba8236458294: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-791d2f7a7d4d4afaab6af8546b4fca9c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-ada5aedebcdc4181822af1282c85d962: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-22ef29a3b50a482092bd6ff0d0afd38e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-93c668a10372495fa14b599d94639d8d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 logger.py:37] Received request chat-1a7338e2a79b41f4ba7580a77d8accf7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:53 engine.py:290] Added request chat-026dc29e011547f58462e1d3c7e023a8.
INFO 11-19 07:05:53 engine.py:290] Added request chat-72e84c9a527e4e4a99a084969cef4c57.
INFO 11-19 07:05:53 engine.py:290] Added request chat-23387c373aba4ae0a641389b5abeefa7.
INFO 11-19 07:05:53 engine.py:290] Added request chat-305916b90d0042ecba9fba8236458294.
INFO 11-19 07:05:53 engine.py:290] Added request chat-791d2f7a7d4d4afaab6af8546b4fca9c.
INFO 11-19 07:05:53 engine.py:290] Added request chat-ada5aedebcdc4181822af1282c85d962.
INFO 11-19 07:05:53 engine.py:290] Added request chat-22ef29a3b50a482092bd6ff0d0afd38e.
INFO 11-19 07:05:53 engine.py:290] Added request chat-93c668a10372495fa14b599d94639d8d.
INFO 11-19 07:05:53 engine.py:290] Added request chat-1a7338e2a79b41f4ba7580a77d8accf7.
INFO 11-19 07:05:54 metrics.py:349] Avg prompt throughput: 14411.8 tokens/s, Avg generation throughput: 39.4 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:54 logger.py:37] Received request chat-c1818646c0844f13b246a6e4d2a52cb4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-95d162bdb88947e3a0547ad2be44e780: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 engine.py:290] Added request chat-c1818646c0844f13b246a6e4d2a52cb4.
INFO 11-19 07:05:54 engine.py:290] Added request chat-95d162bdb88947e3a0547ad2be44e780.
INFO 11-19 07:05:54 logger.py:37] Received request chat-90a7f8aa75364b33b6cc696631b2be6d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-90f0d59bf5b045f78202ffdbabf8f2ce: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-a735998dd78d43548bfa55a41c600bf3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-d44ead2c1c2643eca610d44cd35bc64c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-1f07ea78a9cc433dbdea20dc58afd9d0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-57987a9028f94637bee682a5da9d8111: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-93ab85bd8b444b959cd0cd089d478e18: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 logger.py:37] Received request chat-a9c1ad45cc3a429eb5acd51b6c1f0ce5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:54 engine.py:290] Added request chat-90a7f8aa75364b33b6cc696631b2be6d.
INFO 11-19 07:05:54 engine.py:290] Added request chat-90f0d59bf5b045f78202ffdbabf8f2ce.
INFO 11-19 07:05:54 engine.py:290] Added request chat-a735998dd78d43548bfa55a41c600bf3.
INFO 11-19 07:05:54 engine.py:290] Added request chat-d44ead2c1c2643eca610d44cd35bc64c.
INFO 11-19 07:05:54 engine.py:290] Added request chat-1f07ea78a9cc433dbdea20dc58afd9d0.
INFO 11-19 07:05:54 engine.py:290] Added request chat-57987a9028f94637bee682a5da9d8111.
INFO 11-19 07:05:54 engine.py:290] Added request chat-93ab85bd8b444b959cd0cd089d478e18.
INFO 11-19 07:05:54 engine.py:290] Added request chat-a9c1ad45cc3a429eb5acd51b6c1f0ce5.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:55 logger.py:37] Received request chat-53d4526455e042f58668a5cb20ae18ab: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:55 engine.py:290] Added request chat-53d4526455e042f58668a5cb20ae18ab.
INFO 11-19 07:05:55 logger.py:37] Received request chat-43291ab7131d44dd80c2b36bfbe4c7ac: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:55 logger.py:37] Received request chat-8aa15829f8e04a268788fe81c49df54d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:55 logger.py:37] Received request chat-878eaf7eeb954849b854d04fab9d4d20: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:55 logger.py:37] Received request chat-64b4860c74be4ba9b4c367bc297532c1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:55 logger.py:37] Received request chat-2c1ecca283034f61999f12a8a65d6a61: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:55 logger.py:37] Received request chat-1308d098bcee4833a1e0967421de72c4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:56 logger.py:37] Received request chat-14b278c07e4f4f58970bd47e836e8e81: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:56 logger.py:37] Received request chat-e0381ebe41df47bebd85da187efd3054: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:56 engine.py:290] Added request chat-43291ab7131d44dd80c2b36bfbe4c7ac.
INFO 11-19 07:05:56 engine.py:290] Added request chat-8aa15829f8e04a268788fe81c49df54d.
INFO 11-19 07:05:56 engine.py:290] Added request chat-878eaf7eeb954849b854d04fab9d4d20.
INFO 11-19 07:05:56 engine.py:290] Added request chat-64b4860c74be4ba9b4c367bc297532c1.
INFO 11-19 07:05:56 engine.py:290] Added request chat-2c1ecca283034f61999f12a8a65d6a61.
INFO 11-19 07:05:56 logger.py:37] Received request chat-c02d61b446fc492aab55aca1ee4a6d2d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:56 engine.py:290] Added request chat-1308d098bcee4833a1e0967421de72c4.
INFO 11-19 07:05:56 engine.py:290] Added request chat-14b278c07e4f4f58970bd47e836e8e81.
INFO 11-19 07:05:56 engine.py:290] Added request chat-e0381ebe41df47bebd85da187efd3054.
INFO 11-19 07:05:56 engine.py:290] Added request chat-c02d61b446fc492aab55aca1ee4a6d2d.
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:57 logger.py:37] Received request chat-7c40bb03cab246a3b943a2af83fa954f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 engine.py:290] Added request chat-7c40bb03cab246a3b943a2af83fa954f.
INFO 11-19 07:05:57 logger.py:37] Received request chat-545561ae532442b387151b671601c32a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-90ec10a02de042d4a85df8822d671b4b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-138ff781f541490d838b63c18941369f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-3af61592235c45049c98ff83b7a41467: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-34ec2de0feba4b72b2cbb13a39491a00: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-e7503f8ecaf84f51abd5ca9fd30d9e6d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-e8b5729d4bc942fc9f2cc93466fb1dc3: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-dd96bf42bcae439a8078e84c95ba7352: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 logger.py:37] Received request chat-82880fe18c59439bbadeb497c86a08dc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:57 engine.py:290] Added request chat-545561ae532442b387151b671601c32a.
INFO 11-19 07:05:57 engine.py:290] Added request chat-90ec10a02de042d4a85df8822d671b4b.
INFO 11-19 07:05:57 engine.py:290] Added request chat-138ff781f541490d838b63c18941369f.
INFO 11-19 07:05:57 engine.py:290] Added request chat-3af61592235c45049c98ff83b7a41467.
INFO 11-19 07:05:57 engine.py:290] Added request chat-34ec2de0feba4b72b2cbb13a39491a00.
INFO 11-19 07:05:57 engine.py:290] Added request chat-e7503f8ecaf84f51abd5ca9fd30d9e6d.
INFO 11-19 07:05:57 engine.py:290] Added request chat-e8b5729d4bc942fc9f2cc93466fb1dc3.
INFO 11-19 07:05:57 engine.py:290] Added request chat-dd96bf42bcae439a8078e84c95ba7352.
INFO 11-19 07:05:57 engine.py:290] Added request chat-82880fe18c59439bbadeb497c86a08dc.
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:58 logger.py:37] Received request chat-7e55b9b57e134c2d8f4b463fd4269203: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 engine.py:290] Added request chat-7e55b9b57e134c2d8f4b463fd4269203.
INFO 11-19 07:05:58 logger.py:37] Received request chat-842e2c94684a40fcbf7a94d7e52977f7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-9b4a53483a014525a59b290fbfceee92: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-4fee8ccc2743412b993045db7550cac7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-72149df3ad0a4a1d8e05dcce32aa5799: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-8ae70157a89a494d8471d6ba1d143940: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-ab8fd420b817461e90194c2a39bdc606: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-8c86dbf6a7484b5299e3c8869120aa60: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-fd55672c190142698248d97ffe797d30: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 logger.py:37] Received request chat-424c31457b904a35acd79af4971477d5: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:58 engine.py:290] Added request chat-842e2c94684a40fcbf7a94d7e52977f7.
INFO 11-19 07:05:58 engine.py:290] Added request chat-9b4a53483a014525a59b290fbfceee92.
INFO 11-19 07:05:58 engine.py:290] Added request chat-4fee8ccc2743412b993045db7550cac7.
INFO 11-19 07:05:58 engine.py:290] Added request chat-72149df3ad0a4a1d8e05dcce32aa5799.
INFO 11-19 07:05:58 engine.py:290] Added request chat-8ae70157a89a494d8471d6ba1d143940.
INFO 11-19 07:05:58 engine.py:290] Added request chat-ab8fd420b817461e90194c2a39bdc606.
INFO 11-19 07:05:58 engine.py:290] Added request chat-8c86dbf6a7484b5299e3c8869120aa60.
INFO 11-19 07:05:58 engine.py:290] Added request chat-fd55672c190142698248d97ffe797d30.
INFO 11-19 07:05:58 engine.py:290] Added request chat-424c31457b904a35acd79af4971477d5.
INFO 11-19 07:05:59 metrics.py:349] Avg prompt throughput: 13941.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 9 reqs, Swapped: 0 reqs, Pending: 1 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:05:59 logger.py:37] Received request chat-8f2fba0e57a34bc3a47f5aba54454f3e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-a5f38bfa9b7547598e1ad4c5e3860b85: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 engine.py:290] Added request chat-8f2fba0e57a34bc3a47f5aba54454f3e.
INFO 11-19 07:05:59 logger.py:37] Received request chat-45b3216511334b16aee8acf9ab3e3503: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-0d1d4f6151494662bac06521e11ac169: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-a8495599c1fd40e98abdad6e78f5a403: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-1262426c21ba47dc9be3628c6955f9fc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-7d6c9fdaf7144de79018fcec3661fc02: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-b697efa9445f4908bfebeb2e42239215: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-95bb139bbb17459695582c7ea5d34468: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 logger.py:37] Received request chat-4ce297fdddc142a384d5a1c56a4c27e1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:05:59 engine.py:290] Added request chat-a5f38bfa9b7547598e1ad4c5e3860b85.
INFO 11-19 07:05:59 engine.py:290] Added request chat-45b3216511334b16aee8acf9ab3e3503.
INFO 11-19 07:05:59 engine.py:290] Added request chat-0d1d4f6151494662bac06521e11ac169.
INFO 11-19 07:05:59 engine.py:290] Added request chat-a8495599c1fd40e98abdad6e78f5a403.
INFO 11-19 07:05:59 engine.py:290] Added request chat-1262426c21ba47dc9be3628c6955f9fc.
INFO 11-19 07:05:59 engine.py:290] Added request chat-7d6c9fdaf7144de79018fcec3661fc02.
INFO 11-19 07:05:59 engine.py:290] Added request chat-b697efa9445f4908bfebeb2e42239215.
INFO 11-19 07:05:59 engine.py:290] Added request chat-95bb139bbb17459695582c7ea5d34468.
INFO 11-19 07:05:59 engine.py:290] Added request chat-4ce297fdddc142a384d5a1c56a4c27e1.
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:06:01 logger.py:37] Received request chat-ef4685617dce4d4ca2fe18dfd0e3cf50: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 engine.py:290] Added request chat-ef4685617dce4d4ca2fe18dfd0e3cf50.
INFO 11-19 07:06:01 logger.py:37] Received request chat-79041cb1b9fc435587f88e0d774da43e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-d8c9c225a4a94c2988ff5b6ffe100e9c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-c09a5639bfb64a61847ba531958141de: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-27b17851dc164f1abc07e5d5edf4694d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-c35a27fcfa3f4bbb947b0124431ebde2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-6a4f4a3ab1764b848cb1024ceec429c8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-8763521e7d2c4f939cc8d8e2d67798cc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-db7abfca962f46cf8b683b4db26e9535: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 logger.py:37] Received request chat-a1a66c264b7442a1b9818bb224120d8b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:01 engine.py:290] Added request chat-79041cb1b9fc435587f88e0d774da43e.
INFO 11-19 07:06:01 engine.py:290] Added request chat-d8c9c225a4a94c2988ff5b6ffe100e9c.
INFO 11-19 07:06:01 engine.py:290] Added request chat-c09a5639bfb64a61847ba531958141de.
INFO 11-19 07:06:01 engine.py:290] Added request chat-27b17851dc164f1abc07e5d5edf4694d.
INFO 11-19 07:06:01 engine.py:290] Added request chat-c35a27fcfa3f4bbb947b0124431ebde2.
INFO 11-19 07:06:01 engine.py:290] Added request chat-6a4f4a3ab1764b848cb1024ceec429c8.
INFO 11-19 07:06:01 engine.py:290] Added request chat-8763521e7d2c4f939cc8d8e2d67798cc.
INFO 11-19 07:06:01 engine.py:290] Added request chat-db7abfca962f46cf8b683b4db26e9535.
INFO 11-19 07:06:01 engine.py:290] Added request chat-a1a66c264b7442a1b9818bb224120d8b.
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:06:02 logger.py:37] Received request chat-e0e03551b0454baa885af38c6f577fe9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 engine.py:290] Added request chat-e0e03551b0454baa885af38c6f577fe9.
INFO 11-19 07:06:02 logger.py:37] Received request chat-4317ea87bdb049eca67cdaf5241de0e8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-721fbc1d99c74396b4a913c81861150f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-259195d555b64effb20574ec642f5090: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-98b5eb0a1ea5481ebd9e920553264f7a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-33a7639334b347bf87357229686e7a1b: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-1939bed04dda41f4bec681c6ceb5d13f: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-2dce280532bb42cda04a29ff716fefa1: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-eb850c6e5e054c1ebc311c9bacedaff8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 logger.py:37] Received request chat-4e8c98819a3348bd9f10e9e444f05674: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:02 engine.py:290] Added request chat-4317ea87bdb049eca67cdaf5241de0e8.
INFO 11-19 07:06:02 engine.py:290] Added request chat-721fbc1d99c74396b4a913c81861150f.
INFO 11-19 07:06:02 engine.py:290] Added request chat-259195d555b64effb20574ec642f5090.
INFO 11-19 07:06:02 engine.py:290] Added request chat-98b5eb0a1ea5481ebd9e920553264f7a.
INFO 11-19 07:06:02 engine.py:290] Added request chat-33a7639334b347bf87357229686e7a1b.
INFO 11-19 07:06:02 engine.py:290] Added request chat-1939bed04dda41f4bec681c6ceb5d13f.
INFO 11-19 07:06:02 engine.py:290] Added request chat-2dce280532bb42cda04a29ff716fefa1.
INFO 11-19 07:06:02 engine.py:290] Added request chat-eb850c6e5e054c1ebc311c9bacedaff8.
INFO 11-19 07:06:02 engine.py:290] Added request chat-4e8c98819a3348bd9f10e9e444f05674.
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:06:03 logger.py:37] Received request chat-f3abf4e07a254e80b2488731eda04399: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 engine.py:290] Added request chat-f3abf4e07a254e80b2488731eda04399.
INFO 11-19 07:06:03 logger.py:37] Received request chat-3357b03675b142b2bbd634a270cbf6a9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-6b19f420b73b4c68a00cdd80514ce71a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-cdae4bb4e5f04f96a0cc34e7340bd5ab: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-d43227367040483bab4d8500b4894c0a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-005f97d3fbda44fc9a4329836ffd1029: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-0390f990678144c0927bea1692dbe021: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-828e1b301cbe48249dd6dc2e8463c040: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-46797517912c490cbb3256501eca84e8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 logger.py:37] Received request chat-8c1c31f4da9e489bac9898bd0c7c692e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:03 engine.py:290] Added request chat-3357b03675b142b2bbd634a270cbf6a9.
INFO 11-19 07:06:03 engine.py:290] Added request chat-6b19f420b73b4c68a00cdd80514ce71a.
INFO 11-19 07:06:03 engine.py:290] Added request chat-cdae4bb4e5f04f96a0cc34e7340bd5ab.
INFO 11-19 07:06:03 engine.py:290] Added request chat-d43227367040483bab4d8500b4894c0a.
INFO 11-19 07:06:03 engine.py:290] Added request chat-005f97d3fbda44fc9a4329836ffd1029.
INFO 11-19 07:06:03 engine.py:290] Added request chat-0390f990678144c0927bea1692dbe021.
INFO 11-19 07:06:03 engine.py:290] Added request chat-828e1b301cbe48249dd6dc2e8463c040.
INFO 11-19 07:06:03 engine.py:290] Added request chat-46797517912c490cbb3256501eca84e8.
INFO 11-19 07:06:03 engine.py:290] Added request chat-8c1c31f4da9e489bac9898bd0c7c692e.
INFO 11-19 07:06:04 metrics.py:349] Avg prompt throughput: 14708.5 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 10 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:06:04 logger.py:37] Received request chat-ae8dd131b02246caad3f92fcfc99c1bc: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 logger.py:37] Received request chat-ab6c394311a043e9b01df4e6942cb731: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 logger.py:37] Received request chat-8cb3b89255ea4029a1a57a6a00f0c4d7: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 engine.py:290] Added request chat-ae8dd131b02246caad3f92fcfc99c1bc.
INFO 11-19 07:06:04 engine.py:290] Added request chat-ab6c394311a043e9b01df4e6942cb731.
INFO 11-19 07:06:04 logger.py:37] Received request chat-92da73c4ca4247f194c21dc12bf4e2a8: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 engine.py:290] Added request chat-8cb3b89255ea4029a1a57a6a00f0c4d7.
INFO 11-19 07:06:04 logger.py:37] Received request chat-9b6dd034b6594649be22cc2a73cbeeed: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 logger.py:37] Received request chat-aa1e543935624b7cbc774f32a3694c2c: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 logger.py:37] Received request chat-dfbbe36259aa4154b5b26708ed88cae0: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 logger.py:37] Received request chat-40318e29081a413eb69e11a6c2bf9697: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 logger.py:37] Received request chat-f4bd5b72c2944983ab5906074c61705d: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 logger.py:37] Received request chat-3fc4ba7e82c245afa0cd4cf2487bf9aa: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:04 engine.py:290] Added request chat-92da73c4ca4247f194c21dc12bf4e2a8.
INFO 11-19 07:06:04 engine.py:290] Added request chat-9b6dd034b6594649be22cc2a73cbeeed.
INFO 11-19 07:06:04 engine.py:290] Added request chat-aa1e543935624b7cbc774f32a3694c2c.
INFO 11-19 07:06:04 engine.py:290] Added request chat-dfbbe36259aa4154b5b26708ed88cae0.
INFO 11-19 07:06:04 engine.py:290] Added request chat-40318e29081a413eb69e11a6c2bf9697.
INFO 11-19 07:06:04 engine.py:290] Added request chat-f4bd5b72c2944983ab5906074c61705d.
INFO 11-19 07:06:04 engine.py:290] Added request chat-3fc4ba7e82c245afa0cd4cf2487bf9aa.
INFO:     127.0.0.1:60024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60052 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:59990 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60066 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:60046 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 11-19 07:06:05 logger.py:37] Received request chat-fc0c621a642448379f1a1eeabd68fe80: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 engine.py:290] Added request chat-fc0c621a642448379f1a1eeabd68fe80.
INFO 11-19 07:06:05 logger.py:37] Received request chat-cc5cd0bf50c1422883e51a0a39636ce4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-8b8a920a08024787a57823525e93d071: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-08771bb178bf4e8d8e949d629fc2f112: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-bf08b536f19b47e386f1f0559811d5c4: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-1106a3fec4e44505a73bdb9d32b5c5e9: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-4dac4c78c721433caaefebe1794a887e: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-eff076e83821471a830b6758530efa58: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-a3b2cb1eba204228ae981a250f2586a2: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 logger.py:37] Received request chat-b700d75fa3f94871a3ba56a3315a7a9a: prompt: '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n<image>\ncraft item crafting table<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=1.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=1024, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), guided_decoding=GuidedDecodingParams(json=None, regex=None, choice=None, grammar=None, json_object=None, backend=None, whitespace_pattern=None), prompt_token_ids: [128000, 128006, 882, 128007, 271, 128256, 198, 7868, 1537, 45167, 2007, 128009, 128006, 78191, 128007, 271], lora_request: None, prompt_adapter_request: None.
INFO 11-19 07:06:05 engine.py:290] Added request chat-cc5cd0bf50c1422883e51a0a39636ce4.
INFO 11-19 07:06:05 engine.py:290] Added request chat-8b8a920a08024787a57823525e93d071.
INFO 11-19 07:06:05 engine.py:290] Added request chat-08771bb178bf4e8d8e949d629fc2f112.
INFO 11-19 07:06:05 engine.py:290] Added request chat-bf08b536f19b47e386f1f0559811d5c4.
INFO 11-19 07:06:05 engine.py:290] Added request chat-1106a3fec4e44505a73bdb9d32b5c5e9.
INFO 11-19 07:06:05 engine.py:290] Added request chat-4dac4c78c721433caaefebe1794a887e.
INFO 11-19 07:06:05 engine.py:290] Added request chat-eff076e83821471a830b6758530efa58.
INFO 11-19 07:06:05 engine.py:290] Added request chat-a3b2cb1eba204228ae981a250f2586a2.
INFO 11-19 07:06:05 engine.py:290] Added request chat-b700d75fa3f94871a3ba56a3315a7a9a.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-fc0c621a642448379f1a1eeabd68fe80.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-cc5cd0bf50c1422883e51a0a39636ce4.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-8b8a920a08024787a57823525e93d071.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-08771bb178bf4e8d8e949d629fc2f112.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-bf08b536f19b47e386f1f0559811d5c4.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-1106a3fec4e44505a73bdb9d32b5c5e9.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-4dac4c78c721433caaefebe1794a887e.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-eff076e83821471a830b6758530efa58.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-a3b2cb1eba204228ae981a250f2586a2.
INFO 11-19 07:06:06 engine.py:308] Aborted request chat-b700d75fa3f94871a3ba56a3315a7a9a.
INFO 11-19 07:06:08 launcher.py:57] Shutting down FastAPI HTTP server.
INFO 11-19 07:06:08 multiproc_worker_utils.py:133] Terminating local vLLM worker processes
[1;36m(VllmWorkerProcess pid=3474563)[0;0m INFO 11-19 07:06:08 multiproc_worker_utils.py:240] Worker exiting
[rank0]:[W1119 07:06:10.445494447 CudaIPCTypes.cpp:16] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
/home/mc_lmy/miniconda3/envs/mark2/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
