/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 
--master_addr=127.0.0.1 
--master_port=20002 
--enable_each_rank_log=None ultron/model/train/vsft.py

--dataset_name /home/mc_lmy/datas/11-10-craft-craft_table-shell_agent-hard/output/11-10-craft-craft_table-shell_agent-hard-llama-3 
--model_name_or_path /scratch/mc_lmy/models/llama3-llava-next-8b-hf 
--dataloader_num_workers 8
--report_to wandb 
--learning_rate 1.4e-4 
--weight_decay 0. 
--warmup_ratio 0.3 
--lr_scheduler_type cosine 
--per_device_train_batch_size 16 
--per_device_eval_batch_size 16 
--gradient_accumulation_steps 4 
--evaluation_strategy steps 
--eval_steps 100 
--save_strategy steps 
--save_steps 100 
--save_total_limit 30 
 
--output_dir /scratch/mc_lmy/models/JARVIS/checkpoints/mc_llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4 
--run_name mc_llama3-llava-next-8b-hf-craft-craft_table-shell_agent-hard-llama-3-11-17-1-A100-c4-e3-b16-a4
--logging_strategy steps 
--logging_steps 1 
--num_train_epochs 3 
--gradient_checkpointing 
--torch_dtype bfloat16 
--bf16 True 
--remove_unused_columns False
--max_seq_length 2048 

--use_peft True 
--lora_r 64 
--lora_alpha 16 
--private_lora_structure 

--deepspeed configs/deepspeed_config_s2.json